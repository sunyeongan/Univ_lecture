{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 전처리 : 질문 및 응답 쌍을 벡터화 된 형식으로 변환해 모델 학습에 활용\n",
    "# 2. 모델 구축 및 검증 : 딥러닝 모델을 개발하고 데이터를 검증\n",
    "# 3. 학습된 모델의 응답 예측 ; 학습된 모델은 주어진 질문에 대한 응답을 예측하는데 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Questions                                            Answers  \\\n",
      "0               yahoo  a lot of people hear about <bot name=\"name\"/> ...   \n",
      "1        you are lazy                    actually i work 24 hours a day.   \n",
      "2         you are mad                no i am quite logical and rational.   \n",
      "3    you are thinking  i am a thinking machine.<think><set name=\"it\">...   \n",
      "4  you are dividing *            actually i am not too good at division.   \n",
      "\n",
      "                                             QnAcomb  \n",
      "0  yahoo a lot of people hear about <bot name=\"na...  \n",
      "1       you are lazy actually i work 24 hours a day.  \n",
      "2    you are mad no i am quite logical and rational.  \n",
      "3  you are thinking i am a thinking machine.<thin...  \n",
      "4  you are dividing * actually i am not too good ...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# File reading\n",
    "\n",
    "with open('/Users/anseon-yeong/수업/2021-2/텍스트정보처리/week13/13주차_txt/bot.txt', 'r') as content_file:\n",
    "    botdata = content_file.read()\n",
    "    \n",
    "   \n",
    "Questions = []\n",
    "Answers = []\n",
    "\n",
    "for line in botdata.split(\"</pattern>\"):\n",
    "    if \"<pattern>\" in line:\n",
    "        Quesn = line[line.find(\"<pattern>\")+len(\"<pattern>\"):]\n",
    "        Questions.append(Quesn.lower())\n",
    "        \n",
    "\n",
    "for line in botdata.split(\"</template>\"):\n",
    "    if \"<template>\" in line:\n",
    "        Ans = line[line.find(\"<template>\")+len(\"<template>\"):]\n",
    "        Ans = Ans.lower()\n",
    "        Answers.append(Ans.lower())\n",
    "  \n",
    "\n",
    "QnAdata = pd.DataFrame(np.column_stack([Questions,Answers]),columns = [\"Questions\",\"Answers\"])\n",
    "QnAdata[\"QnAcomb\"] = QnAdata[\"Questions\"]+\" \"+QnAdata[\"Answers\"]\n",
    "\n",
    "\n",
    "print(QnAdata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vocabulary size: 3451\n"
     ]
    }
   ],
   "source": [
    "# Creating Vocabulary\n",
    "import nltk\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter()\n",
    "\n",
    "for i in range(len(QnAdata)):\n",
    "    for word in nltk.word_tokenize(QnAdata.iloc[i][2]):\n",
    "        counter[word]+=1\n",
    "\n",
    "word2idx = {w:(i+1) for i,(w,_) in enumerate(counter.most_common())}        \n",
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "\n",
    "\n",
    "idx2word[0] = \"PAD\"\n",
    "\n",
    "vocab_size = len(word2idx)+1\n",
    "\n",
    "print(\"\\n\\nVocabulary size:\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence, maxlen,vocab_size):\n",
    "    indices = np.zeros((maxlen, vocab_size))\n",
    "    for i, w in enumerate(nltk.word_tokenize(sentence)):\n",
    "        if i == maxlen: break\n",
    "        indices[i, word2idx[w]] = 1\n",
    "    return indices\n",
    "\n",
    "\n",
    "def decode(indices, calc_argmax=True):\n",
    "    if calc_argmax:\n",
    "        indices = np.argmax(indices, axis=-1)\n",
    "    return ' '.join(idx2word[x] for x in indices)\n",
    "\n",
    "\n",
    "question_maxlen = 10\n",
    "answer_maxlen = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_questions(question_maxlen,vocab_size):\n",
    "    question_idx = np.zeros(shape=(len(Questions),question_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Questions)):\n",
    "        question = encode(Questions[q],question_maxlen,vocab_size)\n",
    "\n",
    "        question_idx[i] = question \n",
    "    return question_idx\n",
    "\n",
    "quesns_train = create_questions(question_maxlen=question_maxlen,vocab_size=vocab_size)\n",
    "\n",
    "\n",
    "def create_answers(answer_maxlen,vocab_size):\n",
    "    answer_idx = np.zeros(shape=(len(Answers),answer_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Answers)):\n",
    "        answer = encode(Answers[q],answer_maxlen,vocab_size)\n",
    "\n",
    "        answer_idx[i] = answer \n",
    "    return answer_idx\n",
    "\n",
    "answs_train = create_answers(answer_maxlen=answer_maxlen,vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 3451)]        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               1832960   \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 20, 3451)          445179    \n",
      "_________________________________________________________________\n",
      "activity_regularization (Act (None, 20, 3451)          0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 3451)          0         \n",
      "=================================================================\n",
      "Total params: 2,278,139\n",
      "Trainable params: 2,278,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.layers import Input,Dense,Dropout,Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import RepeatVector,TimeDistributed,ActivityRegularization\n",
    "\n",
    "\n",
    "\n",
    "n_hidden = 128\n",
    "\n",
    "\n",
    "question_layer = Input(shape=(question_maxlen,vocab_size))\n",
    "\n",
    "encoder_rnn = LSTM(n_hidden,dropout=0.2,recurrent_dropout=0.2)(question_layer)\n",
    "\n",
    "repeat_encode = RepeatVector(answer_maxlen)(encoder_rnn)\n",
    "\n",
    "dense_layer = TimeDistributed(Dense(vocab_size))(repeat_encode)\n",
    "\n",
    "regularized_layer = ActivityRegularization(l2=1)(dense_layer)\n",
    "    \n",
    "softmax_layer = Activation('softmax')(regularized_layer)\n",
    "\n",
    "\n",
    "model = Model([question_layer],[softmax_layer])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "quesns_train_2 = quesns_train.astype('float32')\n",
    "answs_train_2 = answs_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "88/88 [==============================] - 15s 128ms/step - loss: 0.0081 - accuracy: 0.0570 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 1.3614e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 7.7846e-06 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 4.8461e-06 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 3.9888e-06 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 4.7461e-06 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 7.6742e-06 - accuracy: 0.0000e+00 - val_loss: 0.0552 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 1.8173e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 1.5652e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 1.5550e-05 - accuracy: 0.0000e+00 - val_loss: 0.0552 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 4.3045e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 4.6259e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 3.3477e-05 - accuracy: 0.0000e+00 - val_loss: 0.0552 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 3.0459e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 6.8209e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 4.9645e-05 - accuracy: 0.0000e+00 - val_loss: 0.0552 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 3.5987e-05 - accuracy: 0.0000e+00 - val_loss: 0.0552 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 6.5428e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 5.1395e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 3.8557e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 5.5613e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "88/88 [==============================] - 8s 95ms/step - loss: 4.2548e-05 - accuracy: 0.0000e+00 - val_loss: 0.0552 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 7.1960e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 4.5938e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 5.2231e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 4.8338e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 4.3225e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 4.7135e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "88/88 [==============================] - 8s 95ms/step - loss: 5.2946e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "88/88 [==============================] - 8s 94ms/step - loss: 5.5760e-05 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd900efa160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(quesns_train_2, answs_train_2,batch_size=32,epochs=30,validation_split=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews\n",
      "jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews jews\n"
     ]
    }
   ],
   "source": [
    "# Model preidciton\n",
    "ans_pred = model.predict(quesns_train_2[0:3])\n",
    "\n",
    "print (decode(ans_pred[0]))\n",
    "print (decode(ans_pred[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
