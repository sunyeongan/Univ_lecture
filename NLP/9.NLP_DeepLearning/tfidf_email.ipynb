{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=50f143f416973dd2ac5310f2dfbbf98b2f181812701a457966310d7ba749411a\n",
      "  Stored in directory: /Users/anseon-yeong/Library/Caches/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.0 (from versions: 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0rc0, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0, 2.5.1, 2.5.2, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.7.0rc0, 2.7.0rc1, 2.7.0)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow==2.0\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.4.3 in /opt/anaconda3/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: h5py<3.0 in /opt/anaconda3/lib/python3.8/site-packages (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.8/site-packages (from keras==2.4.3) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from keras==2.4.3) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/anaconda3/lib/python3.8/site-packages (from keras==2.4.3) (1.5.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from h5py<3.0) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras==2.4.3 \"h5py<3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "Successfully installed keras-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (2020.10.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"install--upgrade\" - maybe you meant \"install\"\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install--upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"install--upgrade\" - maybe you meant \"install\"\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install--upgrade tensorflow - gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20개 카테고 전체 목록:\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n",
      "\n",
      "샘플 이메일:\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "샘플 타깃 카테고리:\n",
      "7\n",
      "rec.autos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "x_train = newsgroups_train.data\n",
    "x_test = newsgroups_test.data\n",
    "\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "print (\"20개 카테고 전체 목록:\")\n",
    "print (newsgroups_train.target_names)\n",
    "print (\"\\n\")\n",
    "print (\"샘플 이메일:\")\n",
    "print (x_train[0])\n",
    "print (\"샘플 타깃 카테고리:\")\n",
    "print (y_train[0])\n",
    "print (newsgroups_train.target_names[y_train[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    #특수문자 제거 \n",
    "    #단어를 분할해 각 문자에 표준 문장부호가 포함되어있는지 확인\n",
    "    \n",
    "    #표준 문장부호가 있다면 빈칸으로 바꾸고,  아니면 공백으로 바꾸지않음\n",
    "    text2 = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in text]).split())\n",
    "\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text2) for word in#토큰화\n",
    "              nltk.word_tokenize(sent)]\n",
    "    \n",
    "    tokens = [word.lower() for word in tokens]#소문자 바꾸기\n",
    "    \n",
    "    stopwds = stopwords.words('english')#불용어 불러오기 \n",
    "    tokens = [token for token in tokens if token not in stopwds]#불용어 제거\n",
    "    \n",
    "    tokens = [word for word in tokens if len(word)>=3]#단어의 길이가 세글자이상만 저장\n",
    "    \n",
    "    stemmer = PorterStemmer()#접미사가 나오는 단어 스테밍 적용\n",
    "    try:\n",
    "        tokens = [stemmer.stem(word) for word in tokens]#어간추출 \n",
    "\n",
    "    except:\n",
    "        tokens = tokens\n",
    "        \n",
    "    tagged_corpus = pos_tag(tokens)#pos_tag()는 명사에 대한 네 가지 형태와 동사에 대한 여섯 가지형태로 푸마를 반환\n",
    "    \n",
    "    Noun_tags = ['NN','NNP','NNPS','NNS']\n",
    "    Verb_tags = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()#원형 복원 \n",
    "\n",
    "    def prat_lemmatize(token,tag):#pos_tag()와 lemmatize함수의 받아들이는 값이 일치하지 않는 경우를 대비해 만들었음\n",
    "        if tag in Noun_tags:#어떤 단어에 해당하는 태그가 각각의 명사 또는 동사 태그 카테고리에 속하는  경우\n",
    "            return lemmatizer.lemmatize(token,'n')\n",
    "        elif tag in Verb_tags:\n",
    "            return lemmatizer.lemmatize(token,'v')\n",
    "        else:\n",
    "            return lemmatizer.lemmatize(token,'n')\n",
    "    #위의 작업 수행 후 다시 결합해 문자열 형태를 생성해야함! \n",
    "    pre_proc_text =  \" \".join([prat_lemmatize(token,tag) for token,tag in tagged_corpus])             \n",
    "\n",
    "    return pre_proc_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_preprocessed  = []\n",
    "for i in x_train:\n",
    "    x_train_preprocessed.append(preprocessing(i))\n",
    "\n",
    "x_test_preprocessed = []\n",
    "for i in x_test:\n",
    "\tx_test_preprocessed.append(preprocessing(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1, 2),  stop_words='english', \n",
    "                             max_features= 10000,strip_accents='unicode',  norm='l2')\n",
    "\n",
    "x_train_2 = vectorizer.fit_transform(x_train_preprocessed).todense()\n",
    "x_test_2 = vectorizer.transform(x_test_preprocessed).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta,Adam,RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Definiting hyper parameters\n",
    "np.random.seed(1337) \n",
    "nb_classes = 20#이메일 카테고리 20개\n",
    "batch_size = 64#일괄처리 사이즈 \n",
    "nb_epochs = 20\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000)              10001000  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                25050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 10,527,570\n",
      "Trainable params: 10,527,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Deep Layer Model building in Keras\n",
    "#del model\n",
    "\n",
    "model = Sequential()#순차적으로 레이어 층을 더해줌 (순차 모델 정의)\n",
    "\n",
    "model.add(Dense(1000,input_shape= (10000,)))#Dense -> 노드 간에 서로 완전히 연결된 레이어\n",
    "#출력될 뉴련의 수, 입력차원\n",
    "model.add(Activation('relu'))#학습 시 기울기 소실 현상 방지\n",
    "model.add(Dropout(0.5))#일부의 레이어 계산을 생략 \n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))#다중 분류 문제에서 마지막 출력값을 보낼 때 사용 -> 큰 출력값 \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#optimizer -> loss 함수 최적화 \n",
    "print (model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "177/177 [==============================] - 7s 40ms/step - loss: 2.5708\n",
      "Epoch 2/20\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 0.6803\n",
      "Epoch 3/20\n",
      "177/177 [==============================] - 7s 40ms/step - loss: 0.3060\n",
      "Epoch 4/20\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.1891\n",
      "Epoch 5/20\n",
      "177/177 [==============================] - 7s 39ms/step - loss: 0.1195\n",
      "Epoch 6/20\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.0850\n",
      "Epoch 7/20\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.0680\n",
      "Epoch 8/20\n",
      "177/177 [==============================] - 6s 37ms/step - loss: 0.0598\n",
      "Epoch 9/20\n",
      "177/177 [==============================] - 7s 40ms/step - loss: 0.0503\n",
      "Epoch 10/20\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0508\n",
      "Epoch 11/20\n",
      "177/177 [==============================] - 7s 40ms/step - loss: 0.0422\n",
      "Epoch 12/20\n",
      "177/177 [==============================] - 7s 41ms/step - loss: 0.0353\n",
      "Epoch 13/20\n",
      "177/177 [==============================] - 8s 43ms/step - loss: 0.0333\n",
      "Epoch 14/20\n",
      "177/177 [==============================] - 7s 41ms/step - loss: 0.0349\n",
      "Epoch 15/20\n",
      "177/177 [==============================] - 7s 42ms/step - loss: 0.0324\n",
      "Epoch 16/20\n",
      "177/177 [==============================] - 8s 42ms/step - loss: 0.0254\n",
      "Epoch 17/20\n",
      "177/177 [==============================] - 7s 39ms/step - loss: 0.0270\n",
      "Epoch 18/20\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0254\n",
      "Epoch 19/20\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 0.0193\n",
      "Epoch 20/20\n",
      "177/177 [==============================] - 7s 39ms/step - loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# 모델학습\n",
    "model.fit(x_train_2, Y_train, batch_size=batch_size, epochs=nb_epochs,verbose=1)\n",
    "\n",
    "# 모델 예측 \n",
    "y_train_predclass = model.predict_classes(x_train_2,batch_size=batch_size)\n",
    "y_test_predclass = model.predict_classes(x_test_2,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Deep Neural Network  - Train accuracy:\n",
      "\n",
      "Deep Neural Network  - Test accuracy:\n",
      "\n",
      "Deep Neural Network  - Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       480\n",
      "           1       1.00      0.99      1.00       584\n",
      "           2       0.99      1.00      1.00       591\n",
      "           3       1.00      1.00      1.00       590\n",
      "           4       1.00      1.00      1.00       578\n",
      "           5       1.00      1.00      1.00       593\n",
      "           6       1.00      1.00      1.00       585\n",
      "           7       1.00      1.00      1.00       594\n",
      "           8       1.00      1.00      1.00       598\n",
      "           9       1.00      1.00      1.00       597\n",
      "          10       1.00      1.00      1.00       600\n",
      "          11       1.00      1.00      1.00       595\n",
      "          12       1.00      1.00      1.00       591\n",
      "          13       1.00      1.00      1.00       594\n",
      "          14       1.00      1.00      1.00       593\n",
      "          15       1.00      1.00      1.00       599\n",
      "          16       1.00      1.00      1.00       546\n",
      "          17       1.00      1.00      1.00       564\n",
      "          18       1.00      1.00      1.00       465\n",
      "          19       1.00      1.00      1.00       377\n",
      "\n",
      "    accuracy                           1.00     11314\n",
      "   macro avg       1.00      1.00      1.00     11314\n",
      "weighted avg       1.00      1.00      1.00     11314\n",
      "\n",
      "\n",
      "Deep Neural Network  - Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76       319\n",
      "           1       0.74      0.67      0.71       389\n",
      "           2       0.69      0.69      0.69       394\n",
      "           3       0.62      0.73      0.67       392\n",
      "           4       0.76      0.82      0.79       385\n",
      "           5       0.80      0.77      0.79       395\n",
      "           6       0.75      0.85      0.80       390\n",
      "           7       0.87      0.85      0.86       396\n",
      "           8       0.92      0.94      0.93       398\n",
      "           9       0.93      0.90      0.91       397\n",
      "          10       0.94      0.97      0.96       399\n",
      "          11       0.90      0.92      0.91       396\n",
      "          12       0.77      0.65      0.70       393\n",
      "          13       0.87      0.80      0.83       396\n",
      "          14       0.89      0.89      0.89       394\n",
      "          15       0.76      0.90      0.82       398\n",
      "          16       0.79      0.87      0.83       364\n",
      "          17       0.96      0.80      0.87       376\n",
      "          18       0.74      0.66      0.70       310\n",
      "          19       0.60      0.59      0.59       251\n",
      "\n",
      "    accuracy                           0.81      7532\n",
      "   macro avg       0.81      0.80      0.80      7532\n",
      "weighted avg       0.81      0.81      0.81      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "print (\"\\n\\nDeep Neural Network  - Train accuracy:\"),(round(accuracy_score(y_train,y_train_predclass),3))\n",
    "print (\"\\nDeep Neural Network  - Test accuracy:\"),(round(accuracy_score(y_test,y_test_predclass),3))\n",
    "\n",
    "print (\"\\nDeep Neural Network  - Train Classification Report\")\n",
    "print (classification_report(y_train,y_train_predclass))\n",
    "\n",
    "print (\"\\nDeep Neural Network  - Test Classification Report\")\n",
    "print (classification_report(y_test,y_test_predclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
